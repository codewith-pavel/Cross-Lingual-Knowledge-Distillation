{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afcf62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:44:14.727362Z",
     "iopub.status.busy": "2025-01-22T09:44:14.727071Z",
     "iopub.status.idle": "2025-01-22T09:45:24.038654Z",
     "shell.execute_reply": "2025-01-22T09:45:24.037580Z"
    },
    "papermill": {
     "duration": 69.316946,
     "end_time": "2025-01-22T09:45:24.040430",
     "exception": false,
     "start_time": "2025-01-22T09:44:14.723484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path_1 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/LOS_WEEKS_adm_test.csv'  # Replace with your file path\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "file_path_2 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/LOS_WEEKS_adm_train.csv'  # Replace with your file path\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "file_path_3 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/LOS_WEEKS_adm_val.csv'  # Replace with your file path\n",
    "df3 = pd.read_csv(file_path_3)\n",
    "file_path_4 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/MP_IN_adm_test.csv'  # Replace with your file path\n",
    "df4 = pd.read_csv(file_path_4)\n",
    "file_path_5 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/MP_IN_adm_train.csv'  # Replace with your file path\n",
    "df5 = pd.read_csv(file_path_5)\n",
    "file_path_6 = '/kaggle/input/clinical-datasets/AI_Translated/AI_Translated/MIMIC_III/MP_IN_adm_val.csv'  # Replace with your file path\n",
    "df6 = pd.read_csv(file_path_6)\n",
    "file_path_7 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_test.csv'  # Replace with your file path\n",
    "df7 = pd.read_csv(file_path_7)\n",
    "file_path_8 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_train.csv'  # Replace with your file path\n",
    "df8 = pd.read_csv(file_path_8)\n",
    "file_path_9 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_val.csv'  # Replace with your file path\n",
    "df9 = pd.read_csv(file_path_9)\n",
    "file_path_10 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/MP_IN_adm_test.csv'  # Replace with your file path\n",
    "df10 = pd.read_csv(file_path_10)\n",
    "file_path_11 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/MP_IN_adm_train.csv'  # Replace with your file path\n",
    "df11 = pd.read_csv(file_path_11)\n",
    "file_path_12 = '/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/MP_IN_adm_val.csv'  # Replace with your file path\n",
    "df12 = pd.read_csv(file_path_12)\n",
    "file_path_13 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/LOS_WEEKS_adm_test.csv'  # Replace with your file path\n",
    "df13 = pd.read_csv(file_path_13)\n",
    "file_path_14 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/LOS_WEEKS_adm_train.csv'  # Replace with your file path\n",
    "df14 = pd.read_csv(file_path_14)\n",
    "file_path_15 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/LOS_WEEKS_adm_val.csv'  # Replace with your file path\n",
    "df15 = pd.read_csv(file_path_15)\n",
    "file_path_16 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/MP_IN_adm_test.csv'  # Replace with your file path\n",
    "df16 = pd.read_csv(file_path_16)\n",
    "file_path_17 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/MP_IN_adm_train.csv'  # Replace with your file path\n",
    "df17 = pd.read_csv(file_path_17)\n",
    "file_path_18 = '/kaggle/input/clinical-datasets/Prompt_Translated/Prompt_engineered_translated/MIMIC_III/MP_IN_adm_val.csv'  # Replace with your file path\n",
    "df18 = pd.read_csv(file_path_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a55679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:24.047063Z",
     "iopub.status.busy": "2025-01-22T09:45:24.046797Z",
     "iopub.status.idle": "2025-01-22T09:45:24.361652Z",
     "shell.execute_reply": "2025-01-22T09:45:24.360622Z"
    },
    "papermill": {
     "duration": 0.318993,
     "end_time": "2025-01-22T09:45:24.363173",
     "exception": false,
     "start_time": "2025-01-22T09:45:24.044180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking df1 ===\n",
      "DataFrame Shape: (8797, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df2 ===\n",
      "DataFrame Shape: (30421, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df3 ===\n",
      "DataFrame Shape: (4391, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df4 ===\n",
      "DataFrame Shape: (9000, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df5 ===\n",
      "DataFrame Shape: (33954, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    1\n",
      "hospital_expire_flag    0\n",
      "bn                      1\n",
      "en                      1\n",
      "dtype: int64\n",
      "Null values found in the DataFrame.\n",
      "Rows with null values in df5:\n",
      "           id text  hospital_expire_flag   bn   en\n",
      "29192  188188  NaN                     1  NaN  NaN\n",
      "\n",
      "=== Checking df6 ===\n",
      "DataFrame Shape: (4908, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df7 ===\n",
      "DataFrame Shape: (8797, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df8 ===\n",
      "DataFrame Shape: (30421, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df9 ===\n",
      "DataFrame Shape: (4391, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df10 ===\n",
      "DataFrame Shape: (9000, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df11 ===\n",
      "DataFrame Shape: (33954, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    1\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "Null values found in the DataFrame.\n",
      "Rows with null values in df11:\n",
      "           id text  hospital_expire_flag       bn       en\n",
      "29192  188188  NaN                     1  #VALUE!  #VALUE!\n",
      "\n",
      "=== Checking df12 ===\n",
      "DataFrame Shape: (4908, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df13 ===\n",
      "DataFrame Shape: (8797, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df14 ===\n",
      "DataFrame Shape: (30421, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df15 ===\n",
      "DataFrame Shape: (4391, 5)\n",
      "Null Values in Each Column:\n",
      "id           0\n",
      "text         0\n",
      "los_label    0\n",
      "bn           0\n",
      "en           0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df16 ===\n",
      "DataFrame Shape: (9000, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n",
      "\n",
      "=== Checking df17 ===\n",
      "DataFrame Shape: (33954, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    1\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "Null values found in the DataFrame.\n",
      "Rows with null values in df17:\n",
      "           id text  hospital_expire_flag  \\\n",
      "29192  188188  NaN                     1   \n",
      "\n",
      "                                                      bn  \\\n",
      "29192  প্রধান অভিযোগ: হাইপোক্সেমিয়া, কাশি\\n\\nবর্তমান...   \n",
      "\n",
      "                                                      en  \n",
      "29192  Chief complaint: hypoxemia, cough\\n\\nPresent i...  \n",
      "\n",
      "=== Checking df18 ===\n",
      "DataFrame Shape: (4908, 5)\n",
      "Null Values in Each Column:\n",
      "id                      0\n",
      "text                    0\n",
      "hospital_expire_flag    0\n",
      "bn                      0\n",
      "en                      0\n",
      "dtype: int64\n",
      "All values is present\n"
     ]
    }
   ],
   "source": [
    "# Assuming df1 to df18 are loaded as DataFrames\n",
    "dataframes = [f\"df{i}\" for i in range(1, 19)]\n",
    "\n",
    "for df_name in dataframes:\n",
    "    df = eval(df_name)  # Get the DataFrame object by its name\n",
    "    print(f\"\\n=== Checking {df_name} ===\")\n",
    "    \n",
    "    # Display the shape of the DataFrame\n",
    "    print(f\"DataFrame Shape: {df.shape}\")\n",
    "    \n",
    "    # Check for null values\n",
    "    null_values = df.isnull().sum()\n",
    "    print(\"Null Values in Each Column:\")\n",
    "    print(null_values)\n",
    "    \n",
    "    # Check if any null values exist in the DataFrame\n",
    "    if df.isnull().values.any():\n",
    "        print(\"Null values found in the DataFrame.\")\n",
    "        \n",
    "        # Display rows with null values\n",
    "        rows_with_nulls = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Rows with null values in {df_name}:\")\n",
    "        print(rows_with_nulls)\n",
    "    else:\n",
    "        print(\"All values is present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ed865",
   "metadata": {
    "papermill": {
     "duration": 0.00217,
     "end_time": "2025-01-22T09:45:24.367891",
     "exception": false,
     "start_time": "2025-01-22T09:45:24.365721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c7fbca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:24.373394Z",
     "iopub.status.busy": "2025-01-22T09:45:24.373161Z",
     "iopub.status.idle": "2025-01-22T09:45:55.812561Z",
     "shell.execute_reply": "2025-01-22T09:45:55.811694Z"
    },
    "papermill": {
     "duration": 31.444059,
     "end_time": "2025-01-22T09:45:55.814355",
     "exception": false,
     "start_time": "2025-01-22T09:45:24.370296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.6.7\r\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.7) (4.67.1)\r\n",
      "Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nltk\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.6.7 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nltk-3.6.7\r\n",
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.6.7)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=a1014a4c337b2ef790d36dd68830fe5f1d1e9ab7088b174a8266f49e097ebe5f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\r\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\r\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\r\n",
      "Installing collected packages: portalocker, sacrebleu\r\n",
      "Successfully installed portalocker-3.1.1 sacrebleu-2.5.1\r\n",
      "Collecting sacremoses\r\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.11.6)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.67.1)\r\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sacremoses\r\n",
      "Successfully installed sacremoses-0.1.1\r\n",
      "Collecting torchtext\r\n",
      "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\r\n",
      "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.12.14)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchtext) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchtext) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchtext) (2024.2.0)\r\n",
      "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torchtext\r\n",
      "Successfully installed torchtext-0.18.0\r\n",
      "Collecting textstat\r\n",
      "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting pyphen (from textstat)\r\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\r\n",
      "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\r\n",
      "Successfully installed pyphen-0.17.2 textstat-0.7.4\r\n",
      "Collecting bert_score\r\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\r\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.27.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.12.14)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\r\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: bert_score\r\n",
      "Successfully installed bert_score-0.3.13\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement py-meteor (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for py-meteor\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk==3.6.7\n",
    "!pip install rouge-score\n",
    "!pip install sacrebleu\n",
    "!pip install sacremoses\n",
    "!pip install torchtext\n",
    "!pip install textstat\n",
    "!pip install bert_score\n",
    "!pip install py-meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cb509f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:55.825391Z",
     "iopub.status.busy": "2025-01-22T09:45:55.825143Z",
     "iopub.status.idle": "2025-01-22T09:45:57.369294Z",
     "shell.execute_reply": "2025-01-22T09:45:57.368613Z"
    },
    "papermill": {
     "duration": 1.551479,
     "end_time": "2025-01-22T09:45:57.370986",
     "exception": false,
     "start_time": "2025-01-22T09:45:55.819507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sacrebleu.metrics import CHRF, TER\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "import math\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7202d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:57.382178Z",
     "iopub.status.busy": "2025-01-22T09:45:57.381789Z",
     "iopub.status.idle": "2025-01-22T09:45:57.571695Z",
     "shell.execute_reply": "2025-01-22T09:45:57.570703Z"
    },
    "papermill": {
     "duration": 0.19693,
     "end_time": "2025-01-22T09:45:57.573160",
     "exception": false,
     "start_time": "2025-01-22T09:45:57.376230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69652ff",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:57.584555Z",
     "iopub.status.busy": "2025-01-22T09:45:57.584223Z",
     "iopub.status.idle": "2025-01-22T09:45:57.595094Z",
     "shell.execute_reply": "2025-01-22T09:45:57.594457Z"
    },
    "papermill": {
     "duration": 0.018062,
     "end_time": "2025-01-22T09:45:57.596377",
     "exception": false,
     "start_time": "2025-01-22T09:45:57.578315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate perplexity\n",
    "def calculate_perplexity(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate perplexity for a reference and hypothesis.\n",
    "    Here, we define perplexity as a simple inverse probability ratio based on word overlap.\n",
    "    \"\"\"\n",
    "    reference_words = reference.split()\n",
    "    hypothesis_words = hypothesis.split()\n",
    "    match_count = sum(1 for word in hypothesis_words if word in reference_words)\n",
    "    total_words = len(hypothesis_words)\n",
    "    perplexity = math.exp(-match_count / total_words) if total_words > 0 else float(\"inf\")\n",
    "    return perplexity\n",
    "\n",
    "# Define a function to calculate metrics\n",
    "def evaluate_metrics(ref, hyp):\n",
    "    # BLEU Scores\n",
    "    ref_text = word_tokenize(ref)\n",
    "    hyp_text = word_tokenize(hyp)\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    bleu_scores = {\n",
    "        f\"BLEU-{i}\": sentence_bleu([ref.split()], hyp.split(), weights=(1 / i,) * i, smoothing_function=smooth_fn)\n",
    "        for i in range(1, 5)\n",
    "    }\n",
    "    \n",
    "    # ROUGE Scores\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(ref, hyp)\n",
    "    rouge_metrics = {f\"ROUGE-{key.upper()}\": value.fmeasure for key, value in rouge_scores.items()}\n",
    "    \n",
    "    # METEOR\n",
    "    meteor = meteor_score([ref_text], hyp_text)\n",
    "    \n",
    "    # ChrF\n",
    "    chrf = CHRF()\n",
    "    chrf_score = chrf.sentence_score(hyp, [ref]).score\n",
    "    \n",
    "    # TER\n",
    "    ter = TER()\n",
    "    ter_score = ter.sentence_score(hyp, [ref]).score\n",
    "    \n",
    "    # GLEU\n",
    "    gleu_score = sentence_gleu([ref],hyp)\n",
    "    \n",
    "    # Perplexity\n",
    "    perplexity = calculate_perplexity(ref, hyp)\n",
    "    \n",
    "    # Combine all metrics\n",
    "    metrics = {\n",
    "        **bleu_scores,\n",
    "        **rouge_metrics,\n",
    "        \"METEOR\": meteor,\n",
    "        \"ChrF\": chrf_score,\n",
    "        \"TER\": ter_score,\n",
    "        \"GLEU\": gleu_score,\n",
    "        \"Perplexity\": perplexity,\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Define a function to process a file and save evaluation results\n",
    "def process_file(file_path):\n",
    "    # Load the file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure the required columns exist\n",
    "    if not all(col in df.columns for col in [\"text\", \"en\"]):\n",
    "        print(f\"Skipping {file_path}: Missing required columns\")\n",
    "        return\n",
    "    \n",
    "    # Evaluate metrics for each row\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        ref_text = str(row[\"text\"])\n",
    "        hyp_text = str(row[\"en\"])\n",
    "        metrics = evaluate_metrics(ref_text, hyp_text)\n",
    "        results.append(metrics)\n",
    "    \n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    output_file = f\"{file_path}_evaluation_results.csv\"\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved evaluation results to {output_file}\")\n",
    "# Define a function to process only the first 100 rows and save evaluation results\n",
    "def process_first_1000_rows(file_path):\n",
    "    # Load the file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure the required columns exist\n",
    "    if not all(col in df.columns for col in [\"text\", \"en\"]):\n",
    "        print(f\"Skipping {file_path}: Missing required columns\")\n",
    "        return\n",
    "    \n",
    "    # Limit to the first 1000 rows\n",
    "    df = df.head(1000)\n",
    "    \n",
    "    # Evaluate metrics for each row\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        ref_text = str(row[\"text\"])\n",
    "        hyp_text = str(row[\"en\"])\n",
    "        metrics = evaluate_metrics(ref_text, hyp_text)\n",
    "        results.append(metrics)\n",
    "    \n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    basename = os.path.basename(file_path_1)  # Extracts 'LOS_WEEKS_adm_test.csv'\n",
    "    output_file = f\"AI_{os.path.splitext(basename)[0]}_metrics.csv\"  # Adds prefix 'AI_' and suffix '_metrics.csv'\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved evaluation results for the first 1000 rows to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12df8ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:45:57.607455Z",
     "iopub.status.busy": "2025-01-22T09:45:57.607238Z",
     "iopub.status.idle": "2025-01-22T12:07:25.313613Z",
     "shell.execute_reply": "2025-01-22T12:07:25.312670Z"
    },
    "papermill": {
     "duration": 8487.71816,
     "end_time": "2025-01-22T12:07:25.319846",
     "exception": false,
     "start_time": "2025-01-22T09:45:57.601686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation results for the first 1000 rows to AI_LOS_WEEKS_adm_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#process_file(file_path_1)\n",
    "process_first_1000_rows(file_path_1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6521545,
     "sourceId": 10539979,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8595.489992,
   "end_time": "2025-01-22T12:07:27.658858",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-22T09:44:12.168866",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
