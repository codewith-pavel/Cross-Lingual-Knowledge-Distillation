{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10539257,"sourceType":"datasetVersion","datasetId":6521088},{"sourceId":264073,"sourceType":"modelInstanceVersion","modelInstanceId":225881,"modelId":247641}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":18934.447804,"end_time":"2024-09-30T10:31:01.641427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-30T05:15:27.193623","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00f5e5c945994ab2a25802e05d2b74c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2958a273a5624c74aeef53b52b8ecbe5","placeholder":"​","style":"IPY_MODEL_33d9e38d438b481a8fb3359298f96904","value":"pytorch_model.bin: 100%"}},"106ff11ec3a440c29bddca56b1c6ef80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a52e37cf59af41e682e9d9b294365b70","IPY_MODEL_b9f675dafc324fa985f9abf5af23736e","IPY_MODEL_5c5022b65cd04324b895be5d08f2b8fe"],"layout":"IPY_MODEL_3eccdf38dc364d3d8e9db7f2b4314f99"}},"1bc4f342965140218c5c2b4eefa29286":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"262338affce944bba865e2946afb9d9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2958a273a5624c74aeef53b52b8ecbe5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33d9e38d438b481a8fb3359298f96904":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35999fb0e0794d4b806d17309f01342c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eccdf38dc364d3d8e9db7f2b4314f99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48663661d7c44190b875ad18ca065ff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49cb0174ee734deabbd46d3a8f724848":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5359444cbeac42f29b49966d3217ea8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c5022b65cd04324b895be5d08f2b8fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce232a6066274406a0d111ecddf2ef0e","placeholder":"​","style":"IPY_MODEL_f1a528bee1414ef1bdd476cf630f7a28","value":" 428/428 [00:00&lt;00:00, 32.5kB/s]"}},"5cb08ec53da04871bc97853a1dbd4dde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_262338affce944bba865e2946afb9d9a","placeholder":"​","style":"IPY_MODEL_35999fb0e0794d4b806d17309f01342c","value":"vocab.txt: 100%"}},"60020e6f1fdf42a3a56da4c9addce6ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"669c89ef40bd483c82699e0bf4fdd1fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"677c278f393f4103bb4b0292f09ba27b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00f5e5c945994ab2a25802e05d2b74c1","IPY_MODEL_ef563e01f3b748da84a4751f21e2ca92","IPY_MODEL_ca563ba85cf54b5a8eae8c3795ccd67a"],"layout":"IPY_MODEL_48663661d7c44190b875ad18ca065ff2"}},"6ac71724b98a4f448bf50838b53fdfff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73e0743b473144e09c9cf04d3867ed52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cb08ec53da04871bc97853a1dbd4dde","IPY_MODEL_fd894b54afb245cba0873619035433f4","IPY_MODEL_9a61ec5bd2c34cef9bf464cf6e37ac96"],"layout":"IPY_MODEL_e645d0a464e74a699265668fb48d3e0f"}},"9a61ec5bd2c34cef9bf464cf6e37ac96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fab1aebcb18c427e9de4a714019bdfc2","placeholder":"​","style":"IPY_MODEL_1bc4f342965140218c5c2b4eefa29286","value":" 213k/213k [00:00&lt;00:00, 2.98MB/s]"}},"a52e37cf59af41e682e9d9b294365b70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49cb0174ee734deabbd46d3a8f724848","placeholder":"​","style":"IPY_MODEL_f72b853b1be64e7792cdd682ec483c2b","value":"config.json: 100%"}},"b4a11ef429b54fd4a478e3a952e5d446":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9f675dafc324fa985f9abf5af23736e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0b995ab4576453986d0904e4dae3bf7","max":428,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5359444cbeac42f29b49966d3217ea8e","value":428}},"c92c75fb4f9146d9ac5a0feb9cf104b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca563ba85cf54b5a8eae8c3795ccd67a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_669c89ef40bd483c82699e0bf4fdd1fb","placeholder":"​","style":"IPY_MODEL_db82597a952e40ddae0f7507ae308a6f","value":" 433M/433M [00:01&lt;00:00, 296MB/s]"}},"ce232a6066274406a0d111ecddf2ef0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db82597a952e40ddae0f7507ae308a6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e645d0a464e74a699265668fb48d3e0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef563e01f3b748da84a4751f21e2ca92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c92c75fb4f9146d9ac5a0feb9cf104b5","max":433289285,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ac71724b98a4f448bf50838b53fdfff","value":433289285}},"f0b995ab4576453986d0904e4dae3bf7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a528bee1414ef1bdd476cf630f7a28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f72b853b1be64e7792cdd682ec483c2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fab1aebcb18c427e9de4a714019bdfc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd894b54afb245cba0873619035433f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4a11ef429b54fd4a478e3a952e5d446","max":213330,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60020e6f1fdf42a3a56da4c9addce6ab","value":213330}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments","metadata":{"papermill":{"duration":19.564397,"end_time":"2024-09-30T05:15:49.447237","exception":false,"start_time":"2024-09-30T05:15:29.88284","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Train, Validation, Test Dataset\ntrain_dataset = pd.read_csv('/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_train.csv')\nval_dataset = pd.read_csv('/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_val.csv')\ntest_dataset = pd.read_csv('/kaggle/input/clinical-datasets/Google_Translated/Google_Translated/MIMIC_III/LOS_WEEKS_adm_test.csv')","metadata":{"papermill":{"duration":1.893175,"end_time":"2024-09-30T05:15:51.346997","exception":false,"start_time":"2024-09-30T05:15:49.453822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create subplots\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Function to add count labels above bars\ndef add_count_labels(ax):\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() / 2., height + 0.5,  # Positioning the text\n                f'{int(height)}', ha='center', va='bottom', fontsize=10)\n\n# Train Set\nsns.countplot(x='los_label', data=train_dataset, ax=axes[0])\naxes[0].set_title(\"Train Dataset Class Distribution\")\nadd_count_labels(axes[0])\n\n# Validation Set\nsns.countplot(x='los_label', data=val_dataset, ax=axes[1])\naxes[1].set_title(\"Validation Dataset Class Distribution\")\nadd_count_labels(axes[1])\n\n# Test Set\nsns.countplot(x='los_label', data=test_dataset, ax=axes[2])\naxes[2].set_title(\"Test Dataset Class Distribution\")\nadd_count_labels(axes[2])\n\n# Display the plots\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch import nn\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, model1):\n        super(EnsembleModel, self).__init__()\n        self.model1 = model1\n\n    def forward(self, input_ids, attention_mask):\n        output1 = self.model1(input_ids, attention_mask=attention_mask)[0]\n        avg_output = output1\n        return avg_output","metadata":{"papermill":{"duration":0.014189,"end_time":"2024-09-30T05:15:51.366827","exception":false,"start_time":"2024-09-30T05:15:51.352638","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoConfig\n\n# Specify the dropout rate in the configuration\nconfig = AutoConfig.from_pretrained('csebuetnlp/banglabert', \n                                    num_labels=4, \n                                    hidden_dropout_prob=0.2, \n                                    attention_probs_dropout_prob=0.2)\n\n# Load the pre-trained model with the specified configuration\ncore_model = AutoModelForSequenceClassification.from_pretrained('csebuetnlp/banglabert', config=config)","metadata":{"papermill":{"duration":2.955371,"end_time":"2024-09-30T05:15:54.327588","exception":false,"start_time":"2024-09-30T05:15:51.372217","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Choose a tokenizer\ntokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')","metadata":{"papermill":{"duration":0.854094,"end_time":"2024-09-30T05:15:55.245653","exception":false,"start_time":"2024-09-30T05:15:54.391559","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the tokenizer to the training, validation, and test datasets\ntrain_encodings = tokenizer(train_dataset['bn'].tolist(), truncation=True, padding=True, max_length = 512)\nval_encodings = tokenizer(val_dataset['bn'].tolist(), truncation=True, padding=True,  max_length = 512)\ntest_encodings = tokenizer(test_dataset['bn'].tolist(), truncation=True, padding=True , max_length = 512)","metadata":{"papermill":{"duration":36.095414,"end_time":"2024-09-30T05:16:31.347676","exception":false,"start_time":"2024-09-30T05:15:55.252262","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a Dataset for PyTorch\nclass LosDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"papermill":{"duration":0.01585,"end_time":"2024-09-30T05:16:31.370739","exception":false,"start_time":"2024-09-30T05:16:31.354889","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = LosDataset(train_encodings, train_dataset['los_label'].tolist())\nval_dataset = LosDataset(val_encodings, val_dataset['los_label'].tolist())\ntest_dataset = LosDataset(test_encodings, test_dataset['los_label'].tolist())","metadata":{"papermill":{"duration":0.02071,"end_time":"2024-09-30T05:16:31.397754","exception":false,"start_time":"2024-09-30T05:16:31.377044","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\nfrom tqdm import tqdm\nfrom torch import nn\nimport numpy as np\n\n# Create the ensemble model\nensemble_model = EnsembleModel(core_model)","metadata":{"papermill":{"duration":0.013838,"end_time":"2024-09-30T05:16:31.417976","exception":false,"start_time":"2024-09-30T05:16:31.404138","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# list all files in the current directory\nfiles = os.listdir('.')\n\n# filter the ones that start with 'GT_BN_BANGLA_baseline'\ncore_models = [f for f in files if f.startswith('GT_BN_BANGLA_baseline')]\n\nif core_models:\n    print(\"Found models starting with 'GT_BN_BANGLA_baseline':\")\n    for model in core_models:\n        print(model)\n        \n    # get the first (and supposedly only) model\n    model_path = core_models[1]\n\n    # load the model state\n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'GT_BN_BANGLA_baseline'.\")","metadata":{"papermill":{"duration":0.015529,"end_time":"2024-09-30T05:16:31.439862","exception":false,"start_time":"2024-09-30T05:16:31.424333","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ensemble_model","metadata":{"papermill":{"duration":0.012806,"end_time":"2024-09-30T05:16:31.459185","exception":false,"start_time":"2024-09-30T05:16:31.446379","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Push the model to device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nensemble_model = ensemble_model.to(device)","metadata":{"papermill":{"duration":0.348279,"end_time":"2024-09-30T05:16:31.814009","exception":false,"start_time":"2024-09-30T05:16:31.46573","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"papermill":{"duration":0.014851,"end_time":"2024-09-30T05:16:31.835874","exception":false,"start_time":"2024-09-30T05:16:31.821023","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 100\nbest_roc_auc = 0\nmin_delta = 0.0001\nearly_stopping_count = 0\nearly_stopping_patience = 5\ngradient_accumulation_steps = 10\nbest_model_path = \"best_model.pth\"\n\n# Set the optimizer\noptimizer = AdamW(ensemble_model.parameters(), lr=1e-5, weight_decay=0.01)\n\n# Set the scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=50, \n    num_training_steps=len(train_loader) * epochs // gradient_accumulation_steps\n)\n","metadata":{"papermill":{"duration":0.015027,"end_time":"2024-09-30T05:16:32.294291","exception":false,"start_time":"2024-09-30T05:16:32.279264","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.nn import functional as F\nimport torch.nn as nn\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Compute class weights\nclasses = np.unique(train_dataset.labels)  # Get unique class labels\nclass_weights = compute_class_weight('balanced', classes=classes, y=train_dataset.labels)\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Print class weights with corresponding class names\nprint(\"Class Weights:\")\nfor cls, weight in zip(classes, class_weights):\n    print(f\"Class {cls}: Weight {weight}\")\n\nroc_auc_values = []\n# Training loop\nfor epoch in range(0, epochs):\n    ensemble_model.train()\n    train_loss = 0\n    for step, batch in enumerate(tqdm(train_loader)):\n        optimizer.zero_grad() if step % gradient_accumulation_steps == 0 else None\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = ensemble_model(input_ids, attention_mask)\n\n        # Apply cost-sensitive loss\n        loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n        loss = loss_fn(outputs, labels)\n\n        (loss / gradient_accumulation_steps).backward()\n        train_loss += loss.item()\n        \n        if (step + 1) % gradient_accumulation_steps == 0 or (step + 1) == len(train_loader):\n            optimizer.step()\n            scheduler.step()\n\n    # Validation\n    ensemble_model.eval()\n    val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        for batch in tqdm(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = ensemble_model(input_ids, attention_mask)\n\n            loss = loss_fn(outputs, labels)\n            val_loss += loss.item()\n\n            val_preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n            val_labels.append(labels.cpu().numpy())\n\n    val_preds = np.concatenate(val_preds)\n    val_labels = np.concatenate(val_labels)\n    val_loss /= len(val_loader)\n    train_loss /= len(train_loader)\n\n    print(f'Epoch: {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n\n    # Calculate evaluation metrics\n    val_preds_class = np.argmax(val_preds, axis=1)\n    accuracy = accuracy_score(val_labels, val_preds_class)\n    recall = recall_score(val_labels, val_preds_class, average='weighted')\n    precision = precision_score(val_labels, val_preds_class, average='weighted')\n    f1 = f1_score(val_labels, val_preds_class, average='weighted')\n    micro_f1 = f1_score(val_labels, val_preds_class, average='micro')\n    macro_roc_auc = roc_auc_score(val_labels, val_preds, multi_class='ovo', average='macro')\n\n    print(f'Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1: {f1}, Micro F1: {micro_f1}, Macro Roc Auc: {macro_roc_auc}')\n    # Store the ROC-AUC value for this epoch\n    roc_auc_values.append(macro_roc_auc)\n\n    # Implement early stopping\n    if epoch > 0 and macro_roc_auc - best_roc_auc < min_delta:\n        early_stopping_count += 1\n        print(f'EarlyStopping counter: {early_stopping_count} out of {early_stopping_patience}')\n        if early_stopping_count >= early_stopping_patience:\n            print('Early stopping')\n            break\n    else:\n        best_roc_auc = macro_roc_auc\n        early_stopping_count = 0\n        torch.save(ensemble_model.state_dict(), f\"GT_BN_BANGLA_baseline_epoch_{epoch}_roc_{best_roc_auc:.4f}.pth\")\n\n# After training, plot the ROC-AUC curve\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, len(roc_auc_values) + 1), roc_auc_values, marker='o', linestyle='-', color='b', label='ROC-AUC Score')\n\n# Enhancing readability\nplt.title('ROC-AUC Score Progression', fontsize=14, fontweight='bold')\nplt.xlabel('Epoch', fontsize=12)\nplt.ylabel('ROC-AUC Score', fontsize=12)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.legend(fontsize=10, loc='lower right')\nplt.ylim(0.7, 1.0)  # Adjust y-axis range if necessary\n\nplt.show()\n\n# Convert the list of ROC-AUC values and epochs to a DataFrame\nroc_auc_df = pd.DataFrame(roc_auc_values)\n\n# Save the DataFrame to a CSV file\nroc_auc_df.to_csv('roc_auc_per_epoch.csv', index=False)\n\nprint(\"ROC-AUC values per epoch saved to 'roc_auc_per_epoch.csv'\")","metadata":{"papermill":{"duration":18693.303378,"end_time":"2024-09-30T10:28:05.604454","exception":false,"start_time":"2024-09-30T05:16:32.301076","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom torch.nn import functional as F\n        \n# get the first (and supposedly only) model\nmodel_path = \"/kaggle/input/bn_los_test/pytorch/default/1/GT_BN_BANGLA_baseline_epoch_5_roc_0.6882.pth\"\n# load the model state\nensemble_model.load_state_dict(torch.load(model_path))\nprint(f\"Loaded Model: {model_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# list all files in the current directory\nfiles = os.listdir('.')\n\n# filter the ones that start with 'GT_BN_BANGLA_baseline'\ncore_models = [f for f in files if f.startswith('GT_BN_BANGLA_baseline')]\n\nif core_models:\n    print(\"Found models starting with 'GT_BN_BANGLA_baseline':\")\n    for model in core_models:\n        print(model)\n        \n    # get the first (and supposedly only) model\n    model_path = core_models[1]\n\n    # load the model state\n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'GT_BN_BANGLA_baseline'.\")","metadata":{"papermill":{"duration":4.324644,"end_time":"2024-09-30T10:28:13.933254","exception":false,"start_time":"2024-09-30T10:28:09.60861","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Put the model in evaluation mode\nensemble_model.eval()\n\n# Initialize lists to store predictions and true labels\ntest_preds = []\ntest_labels = []\n\n# Iterate over test data\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = ensemble_model(input_ids, attention_mask)\n        test_preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n        test_labels.append(labels.cpu().numpy())\n\n","metadata":{"papermill":{"duration":140.574652,"end_time":"2024-09-30T10:30:38.384025","exception":false,"start_time":"2024-09-30T10:28:17.809373","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_preds = np.concatenate(test_preds)\ntest_labels = np.concatenate(test_labels)\n\n# Calculate metrics\ntest_preds_class = np.argmax(test_preds, axis=1)\naccuracy = accuracy_score(test_labels, test_preds_class)\nrecall = recall_score(test_labels, test_preds_class, average='weighted')\nprecision = precision_score(test_labels, test_preds_class, average='weighted')\nf1 = f1_score(test_labels, test_preds_class, average='weighted')\nmicro_f1 = f1_score(test_labels, test_preds_class, average='micro')\nmacro_roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo', average='macro')\n\nprint(f'Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1: {f1}, Micro F1: {micro_f1}, Macro Roc Auc: {macro_roc_auc}')","metadata":{"papermill":{"duration":4.029713,"end_time":"2024-09-30T10:30:46.458264","exception":false,"start_time":"2024-09-30T10:30:42.428551","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}